{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae53957a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import MaxPooling2D, Conv2D\n",
    "from keras.layers import AvgPool2D, MaxPool2D\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4be52144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6619 images belonging to 2 classes.\n",
      "Found 1004 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = r'E:\\practice\\covid\\covid xray\\train'\n",
    "test_dir = r'E:\\practice\\covid\\covid xray\\test'\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=64,\n",
    "        classes = ['covid','normal'])\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        classes = ['covid','normal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3802cfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation=('relu'), input_shape=(150,150,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation=('relu')))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation=(\"relu\")))\n",
    "model.add(Conv2D(250,(3,3), activation=(\"relu\")))\n",
    "  \n",
    "model.add(Conv2D(128,(3,3), activation=(\"relu\")))\n",
    "model.add(AvgPool2D(2,2))\n",
    "model.add(Conv2D(64,(3,3), activation=(\"relu\")))\n",
    "model.add(AvgPool2D(2,2))\n",
    "\n",
    "model.add(Conv2D(256,(2,2), activation=(\"relu\")))\n",
    "model.add(MaxPool2D(2,2))\n",
    "    \n",
    "model.add(Flatten())\n",
    "model.add(Dense(32))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(2, activation=(\"softmax\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcff8727",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f78c828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4731a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "104/104 [==============================] - 993s 10s/step - loss: 0.3276 - accuracy: 0.8571 - val_loss: 0.0855 - val_accuracy: 0.9203\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 1037s 10s/step - loss: 0.3111 - accuracy: 0.8669 - val_loss: 0.1143 - val_accuracy: 0.9542\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 995s 10s/step - loss: 0.2935 - accuracy: 0.8725 - val_loss: 0.2161 - val_accuracy: 0.9074\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 1347s 13s/step - loss: 0.2665 - accuracy: 0.8867 - val_loss: 0.1818 - val_accuracy: 0.9333\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 1339s 13s/step - loss: 0.2836 - accuracy: 0.8800 - val_loss: 0.1002 - val_accuracy: 0.9243\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "  train_generator,\n",
    "  validation_data=test_generator,\n",
    "  epochs=5  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d53187de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "104/104 [==============================] - 1015s 10s/step - loss: 0.2412 - accuracy: 0.8988 - val_loss: 0.0563 - val_accuracy: 0.9542\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 9320s 90s/step - loss: 0.2252 - accuracy: 0.9062 - val_loss: 0.0421 - val_accuracy: 0.9542\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 987s 9s/step - loss: 0.2118 - accuracy: 0.9142 - val_loss: 0.1843 - val_accuracy: 0.9542\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 991s 10s/step - loss: 0.1989 - accuracy: 0.9190 - val_loss: 0.3252 - val_accuracy: 0.9422\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 984s 9s/step - loss: 0.1846 - accuracy: 0.9266 - val_loss: 0.0795 - val_accuracy: 0.9562\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "  train_generator,\n",
    "  validation_data=test_generator,\n",
    "  epochs=5  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "610ea869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "104/104 [==============================] - 977s 9s/step - loss: 0.1791 - accuracy: 0.9311 - val_loss: 0.1059 - val_accuracy: 0.9183\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 979s 9s/step - loss: 0.1672 - accuracy: 0.9355 - val_loss: 0.6923 - val_accuracy: 0.9721\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 988s 9s/step - loss: 0.1516 - accuracy: 0.9435 - val_loss: 0.0125 - val_accuracy: 0.9821\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 971s 9s/step - loss: 0.1351 - accuracy: 0.9483 - val_loss: 0.1131 - val_accuracy: 0.9771\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 972s 9s/step - loss: 0.1249 - accuracy: 0.9497 - val_loss: 0.0879 - val_accuracy: 0.9671\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "  train_generator,\n",
    "  validation_data=test_generator,\n",
    "  epochs=5  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a75a791a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "104/104 [==============================] - 977s 9s/step - loss: 0.1140 - accuracy: 0.9551 - val_loss: 0.0752 - val_accuracy: 0.9811\n",
      "Epoch 2/3\n",
      "104/104 [==============================] - 971s 9s/step - loss: 0.1081 - accuracy: 0.9574 - val_loss: 0.0129 - val_accuracy: 0.9721\n",
      "Epoch 3/3\n",
      "104/104 [==============================] - 982s 9s/step - loss: 0.1183 - accuracy: 0.9538 - val_loss: 0.1187 - val_accuracy: 0.9851\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "  train_generator,\n",
    "  validation_data=test_generator,\n",
    "  epochs=3 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa62278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'E:\\practice\\covid\\covid19.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35b47fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(r\"E:\\practice\\covid\\covid19.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ca8641b",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r'E:/practice/covid/covid xray/New folder/val/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68e3f3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of images\n",
    "img_width, img_height = 150, 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8fb9886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COVID-1.png\n",
      "COVID-10.png\n",
      "COVID-11.png\n",
      "COVID-2.png\n",
      "COVID-3.png\n",
      "COVID-4.png\n",
      "COVID-5.png\n",
      "COVID-6.png\n",
      "COVID-7.png\n",
      "COVID-8.png\n",
      "COVID-9.png\n",
      "Normal-1.png\n",
      "Normal-10.png\n",
      "Normal-11.png\n",
      "Normal-2.png\n",
      "Normal-3.png\n",
      "Normal-4.png\n",
      "Normal-5.png\n",
      "Normal-6.png\n",
      "Normal-7.png\n",
      "Normal-8.png\n",
      "Normal-9.png\n",
      "[1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.preprocessing import image\n",
    "images = []\n",
    "for img in os.listdir(folder_path):\n",
    "    print(img)\n",
    "    img = os.path.join(folder_path, img)\n",
    "    img = image.load_img(img, target_size=(img_width, img_height))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    images.append(img)\n",
    "\n",
    "# stack up images list to pass for prediction\n",
    "images = np.vstack(images)\n",
    "# print(images)\n",
    "classes = model.predict_classes(images, batch_size=10)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2097d6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal\n",
      "normal\n",
      "normal\n",
      "covid\n",
      "covid\n",
      "normal\n",
      "covid\n",
      "covid\n",
      "normal\n",
      "covid\n",
      "covid\n",
      "normal\n",
      "normal\n",
      "normal\n",
      "covid\n",
      "normal\n",
      "normal\n",
      "normal\n",
      "normal\n",
      "normal\n",
      "normal\n",
      "covid\n"
     ]
    }
   ],
   "source": [
    "for i in classes:\n",
    "    if i == 0:\n",
    "        print('covid')\n",
    "    else:\n",
    "        print('normal')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "41f6c403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "img = r'E:/practice/covid/covid xray/New folder/val/'\n",
    "for filename in os.listdir(img):\n",
    "    if filename.endswith(\".png\"):\n",
    "      #do smth\n",
    "      continue\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0f5c04e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\practice\\covid\\covid xray\\New folder\\val\\COVID-1.png\n",
      "E:\\practice\\covid\\covid xray\\New folder\\val\\COVID-10.png\n",
      "E:\\practice\\covid\\covid xray\\New folder\\val\\COVID-11.png\n",
      "E:\\practice\\covid\\covid xray\\New folder\\val\\COVID-2.png\n",
      "E:\\practice\\covid\\covid xray\\New folder\\val\\COVID-3.png\n",
      "E:\\practice\\covid\\covid xray\\New folder\\val\\COVID-4.png\n",
      "E:\\practice\\covid\\covid xray\\New folder\\val\\COVID-5.png\n",
      "E:\\practice\\covid\\covid xray\\New folder\\val\\COVID-6.png\n",
      "E:\\practice\\covid\\covid xray\\New folder\\val\\COVID-7.png\n",
      "E:\\practice\\covid\\covid xray\\New folder\\val\\COVID-8.png\n",
      "E:\\practice\\covid\\covid xray\\New folder\\val\\COVID-9.png\n",
      "E:\\practice\\covid\\covid xray\\New folder\\val\\Normal-1.png\n",
      "E:\\practice\\covid\\covid xray\\New folder\\val\\Normal-10.png\n",
      "E:\\practice\\covid\\covid xray\\New folder\\val\\Normal-11.png\n",
      "E:\\practice\\covid\\covid xray\\New folder\\val\\Normal-2.png\n",
      "E:\\practice\\covid\\covid xray\\New folder\\val\\Normal-3.png\n",
      "E:\\practice\\covid\\covid xray\\New folder\\val\\Normal-4.png\n",
      "E:\\practice\\covid\\covid xray\\New folder\\val\\Normal-5.png\n",
      "E:\\practice\\covid\\covid xray\\New folder\\val\\Normal-6.png\n",
      "E:\\practice\\covid\\covid xray\\New folder\\val\\Normal-7.png\n",
      "E:\\practice\\covid\\covid xray\\New folder\\val\\Normal-8.png\n",
      "E:\\practice\\covid\\covid xray\\New folder\\val\\Normal-9.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for subdir, dirs, files in os.walk(r'E:\\practice\\covid\\covid xray\\New folder\\val'):\n",
    "    for filename in files:\n",
    "        filepath = subdir + os.sep + filename\n",
    "\n",
    "        if filepath.endswith(\".png\"):\n",
    "            print (filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5641c043",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = r'E:\\practice\\covid\\val\\covid (1).jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f64e828e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_path, show=False):\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150))\n",
    "    img_tensor = image.img_to_array(img)                    # (height, width, channels)\n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
    "    img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n",
    "\n",
    "    if show:\n",
    "        plt.imshow(img_tensor[0])                           \n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2461c406",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = load_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd93b472",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e36c10d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bf303a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covid\n"
     ]
    }
   ],
   "source": [
    "if pred == 0:\n",
    "    print('covid')\n",
    "elif pred == 1:\n",
    "    print('normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc3b079",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
